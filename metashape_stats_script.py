import os
import sys
import psutil
import gc
from PySide2 import QtCore, QtGui, QtWidgets


# Checking compatibility
compatible_major_version = "2.1"
found_major_version = ".".join(Metashape.app.version.split('.')[:2])
if found_major_version != compatible_major_version:
    raise Exception("Incompatible Metashape version: {} != {}".format(found_major_version, compatible_major_version))


def get_memory_usage():
    """è·å–å½“å‰è¿›ç¨‹çš„å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    process = psutil.Process()
    memory_info = process.memory_info()
    return {
        'rss': memory_info.rss,  # ç‰©ç†å†…å­˜ (å­—èŠ‚)
        'vms': memory_info.vms,  # è™šæ‹Ÿå†…å­˜ (å­—èŠ‚)
        'percent': process.memory_percent(),  # å†…å­˜ä½¿ç”¨ç™¾åˆ†æ¯”
        'available': psutil.virtual_memory().available  # å¯ç”¨å†…å­˜
    }

def format_bytes(bytes_value):
    """æ ¼å¼åŒ–å­—èŠ‚æ•°ä¸ºäººç±»å¯è¯»æ ¼å¼"""
    if bytes_value == 0:
        return "0 B"
    
    units = ['B', 'KB', 'MB', 'GB', 'TB']
    unit_index = 0
    value = float(bytes_value)
    
    while value >= 1024 and unit_index < len(units) - 1:
        value /= 1024
        unit_index += 1
    
    return f"{value:.2f} {units[unit_index]}"

def estimate_object_memory_size(obj, max_depth=3, visited=None):
    """ä¼°ç®—Pythonå¯¹è±¡çš„å†…å­˜å¤§å°ï¼ˆé€’å½’ï¼‰"""
    if visited is None:
        visited = set()
    
    if max_depth <= 0 or id(obj) in visited:
        return 0
    
    visited.add(id(obj))
    size = sys.getsizeof(obj)
    
    # æ ¹æ®å¯¹è±¡ç±»å‹è¿›è¡Œé€’å½’ä¼°ç®—
    if isinstance(obj, dict):
        size += sum(estimate_object_memory_size(k, max_depth-1, visited) + 
                   estimate_object_memory_size(v, max_depth-1, visited) 
                   for k, v in obj.items())
    elif isinstance(obj, (list, tuple, set)):
        size += sum(estimate_object_memory_size(item, max_depth-1, visited) 
                   for item in obj)
    elif hasattr(obj, '__dict__'):
        size += estimate_object_memory_size(obj.__dict__, max_depth-1, visited)
    
    return size

def get_tie_points_memory_estimate(tie_points):
    """ä¼°ç®—tie_pointsçš„å†…å­˜ä½¿ç”¨"""
    if not tie_points:
        return 0
    
    memory_estimate = 0
    
    try:
        # ä¼°ç®—pointsæ•°ç»„å†…å­˜
        if hasattr(tie_points, 'points') and tie_points.points:
            points_count = len(tie_points.points)
            # æ¯ä¸ªç‚¹å¤§çº¦åŒ…å«: 3Dåæ ‡(24å­—èŠ‚) + track_id(8å­—èŠ‚) + å…¶ä»–å±æ€§(çº¦32å­—èŠ‚)
            memory_estimate += points_count * 64
        
        # ä¼°ç®—tracksæ•°ç»„å†…å­˜  
        if hasattr(tie_points, 'tracks') and tie_points.tracks:
            tracks_count = len(tie_points.tracks)
            # æ¯ä¸ªtrackå¤§çº¦åŒ…å«: é¢œè‰²(3å­—èŠ‚) + ç½®ä¿¡åº¦(8å­—èŠ‚) + å…¶ä»–å±æ€§(çº¦32å­—èŠ‚)
            memory_estimate += tracks_count * 48
        
        # ä¼°ç®—projectionså†…å­˜ï¼ˆè¿™é€šå¸¸æ˜¯æœ€å¤§çš„éƒ¨åˆ†ï¼‰
        if hasattr(tie_points, 'projections'):
            total_projections = 0
            try:
                # éå†æ‰€æœ‰ç›¸æœºçš„æŠ•å½±
                for camera_projections in tie_points.projections.values():
                    if camera_projections:
                        total_projections += len(camera_projections)
                # æ¯ä¸ªæŠ•å½±: 2Dåæ ‡(16å­—èŠ‚) + track_id(8å­—èŠ‚) + size(8å­—èŠ‚) + å…¶ä»–(32å­—èŠ‚)
                memory_estimate += total_projections * 64
            except:
                # å¦‚æœæ— æ³•éå†ï¼Œä½¿ç”¨ä¼°ç®—
                memory_estimate += points_count * 10 * 64  # å‡è®¾æ¯ä¸ªç‚¹å¹³å‡åœ¨10ä¸ªç›¸æœºä¸­å¯è§
    
    except Exception as e:
        print(f"ä¼°ç®—tie_pointså†…å­˜æ—¶å‡ºé”™: {e}")
        return 0
    
    return memory_estimate

def estimate_export_colmap_memory_usage(frame, calibs=None):
    """ä¼°ç®—æŒ‰ç…§export_colmapåŸç‰ˆè„šæœ¬å¯¼å‡ºæ—¶trackså’Œimageså­—å…¸çš„å†…å­˜å ç”¨"""
    if not frame or not hasattr(frame, 'tie_points') or not frame.tie_points:
        return {
            'tracks_dict_memory': 0,
            'images_dict_memory': 0,
            'total_export_memory': 0,
            'memory_breakdown': {}
        }
    
    tie_points = frame.tie_points
    memory_breakdown = {}
    
    try:
        # æ¨¡æ‹Ÿtrackså­—å…¸çš„å†…å­˜ä½¿ç”¨
        tracks_memory = 0
        points_count = 0
        tracks_count = 0
        
        if hasattr(tie_points, 'points') and tie_points.points:
            points_count = len(tie_points.points)
            
        if hasattr(tie_points, 'tracks') and tie_points.tracks:
            tracks_count = len(tie_points.tracks)
        
        # trackså­—å…¸ç»“æ„: { track_id: [ point indices, good projections, bad projections ] }
        # æ¯ä¸ªtrack_idæ¡ç›®çš„å†…å­˜ä¼°ç®—:
        for track_id in range(tracks_count):
            # Pythonå­—å…¸æ¡ç›®å¼€é”€: key(8å­—èŠ‚) + valueæŒ‡é’ˆ(8å­—èŠ‚) + å“ˆå¸Œè¡¨å¼€é”€(çº¦16å­—èŠ‚)
            dict_entry_overhead = 32
            
            # åˆ—è¡¨ç»“æ„: [point_indices, good_projections, bad_projections]
            # 3ä¸ªåˆ—è¡¨å¯¹è±¡: æ¯ä¸ªåˆ—è¡¨çº¦48å­—èŠ‚åŸºç¡€å¼€é”€
            lists_overhead = 3 * 48
            
            # point_indicesåˆ—è¡¨: é€šå¸¸æ¯ä¸ªtrackåªæœ‰1-3ä¸ªç‚¹ç´¢å¼•
            point_indices_memory = 2 * 8  # å¹³å‡2ä¸ªç‚¹ç´¢å¼•ï¼Œæ¯ä¸ª8å­—èŠ‚
            
            # æŠ•å½±åˆ—è¡¨: ä¼°ç®—æ¯ä¸ªtrackåœ¨å¤šå°‘ç›¸æœºä¸­å¯è§
            avg_projections_per_track = max(1, points_count // tracks_count * 8)  # å‡è®¾å¹³å‡å¯è§åº¦
            good_projections_memory = avg_projections_per_track * 16  # æ¯ä¸ªæŠ•å½±(camera_key, proj_idx)
            bad_projections_memory = avg_projections_per_track * 0.2 * 16  # å‡è®¾20%ä¸ºbadæŠ•å½±
            
            track_total_memory = (dict_entry_overhead + lists_overhead + 
                                 point_indices_memory + good_projections_memory + bad_projections_memory)
            tracks_memory += track_total_memory
        
        # Pythonå­—å…¸æœ¬èº«çš„å¼€é”€ (å“ˆå¸Œè¡¨ã€æ¡¶æ•°ç»„ç­‰)
        tracks_dict_overhead = tracks_count * 1.33 * 8  # å“ˆå¸Œè¡¨è´Ÿè½½å› å­çº¦0.75ï¼ŒåŠ ä¸Šé¢å¤–å¼€é”€
        tracks_memory += tracks_dict_overhead
        
        memory_breakdown['tracks_dict_entries'] = tracks_memory - tracks_dict_overhead
        memory_breakdown['tracks_dict_overhead'] = tracks_dict_overhead
        
        # æ¨¡æ‹Ÿimageså­—å…¸çš„å†…å­˜ä½¿ç”¨
        images_memory = 0
        cameras_count = 0
        
        # è·å–ç›¸æœºæ•°é‡
        if hasattr(frame, 'cameras') and frame.cameras:
            cameras_count = len([cam for cam in frame.cameras 
                               if cam.transform is not None and cam.sensor is not None and cam.enabled])
        
        # imageså­—å…¸ç»“æ„: { camera_key: [ camera, good projections, bad projections ] }
        total_projections = 0
        if hasattr(tie_points, 'projections'):
            try:
                for camera_projections in tie_points.projections.values():
                    if camera_projections:
                        total_projections += len(camera_projections)
            except:
                total_projections = points_count * 8  # ä¼°ç®—å€¼
        
        avg_projections_per_camera = total_projections // max(1, cameras_count) if cameras_count > 0 else 0
        
        for cam_id in range(cameras_count):
            # Pythonå­—å…¸æ¡ç›®å¼€é”€
            dict_entry_overhead = 32
            
            # åˆ—è¡¨ç»“æ„: [camera, good_projections, bad_projections] 
            lists_overhead = 48  # ä¸€ä¸ªåˆ—è¡¨å¯¹è±¡
            camera_ref_memory = 8  # ç›¸æœºå¯¹è±¡å¼•ç”¨
            
            # æŠ•å½±æ•°æ®: (undistorted_pt, size, track_id) å…ƒç»„
            # æ¯ä¸ªæŠ•å½±å…ƒç»„: Vectorå¯¹è±¡(çº¦64å­—èŠ‚) + float(8å­—èŠ‚) + int(8å­—èŠ‚) = 80å­—èŠ‚
            good_projections_memory = avg_projections_per_camera * 0.8 * 80  # å‡è®¾80%ä¸ºgood
            bad_projections_memory = avg_projections_per_camera * 0.2 * 80   # å‡è®¾20%ä¸ºbad
            
            # å¥½æŠ•å½±å’ŒåæŠ•å½±çš„åˆ—è¡¨å¼€é”€
            projection_lists_overhead = 2 * 48  # ä¸¤ä¸ªå­åˆ—è¡¨
            
            camera_total_memory = (dict_entry_overhead + lists_overhead + camera_ref_memory +
                                 good_projections_memory + bad_projections_memory + projection_lists_overhead)
            images_memory += camera_total_memory
        
        # imageså­—å…¸æœ¬èº«çš„å¼€é”€
        images_dict_overhead = cameras_count * 1.33 * 8
        images_memory += images_dict_overhead
        
        memory_breakdown['images_dict_entries'] = images_memory - images_dict_overhead
        memory_breakdown['images_dict_overhead'] = images_dict_overhead
        
        # é¢å¤–çš„å¤„ç†å¼€é”€ï¼ˆä¸´æ—¶å˜é‡ã€è®¡ç®—ç¼“å­˜ç­‰ï¼‰
        processing_overhead = (tracks_memory + images_memory) * 0.15
        memory_breakdown['processing_overhead'] = processing_overhead
        
        total_export_memory = tracks_memory + images_memory + processing_overhead
        
        # è¯¦ç»†åˆ†è§£
        memory_breakdown.update({
            'points_count': points_count,
            'tracks_count': tracks_count,
            'cameras_count': cameras_count,
            'total_projections': total_projections,
            'avg_projections_per_camera': avg_projections_per_camera,
            'tracks_memory_per_entry': tracks_memory / max(1, tracks_count),
            'images_memory_per_camera': images_memory / max(1, cameras_count)
        })
        
        return {
            'tracks_dict_memory': tracks_memory,
            'images_dict_memory': images_memory,
            'total_export_memory': total_export_memory,
            'memory_breakdown': memory_breakdown
        }
        
    except Exception as e:
        print(f"ä¼°ç®—export_colmapå†…å­˜ä½¿ç”¨æ—¶å‡ºé”™: {e}")
        return {
            'tracks_dict_memory': 0,
            'images_dict_memory': 0,
            'total_export_memory': 0,
            'memory_breakdown': {'error': str(e)}
        }

def analyze_frame_statistics(frame):
    """åˆ†æå•ä¸ªframeçš„ç»Ÿè®¡ä¿¡æ¯"""
    stats = {
        'points_count': 0,
        'tracks_count': 0,
        'projections_count': 0,
        'cameras_with_projections': 0,
        'estimated_memory': 0,
        'export_colmap_memory': {}  # ğŸ†• æ–°å¢export_colmapå†…å­˜ä¼°ç®—
    }
    
    if not frame:
        return stats
    
    try:
        # åˆ†ætie_points
        if hasattr(frame, 'tie_points') and frame.tie_points:
            tie_points = frame.tie_points
            
            # ç»Ÿè®¡points
            if hasattr(tie_points, 'points') and tie_points.points:
                stats['points_count'] = len(tie_points.points)
            
            # ç»Ÿè®¡tracks
            if hasattr(tie_points, 'tracks') and tie_points.tracks:
                stats['tracks_count'] = len(tie_points.tracks)
            
            # ç»Ÿè®¡projections
            if hasattr(tie_points, 'projections'):
                total_projections = 0
                cameras_with_proj = 0
                try:
                    for camera_projections in tie_points.projections.values():
                        if camera_projections and len(camera_projections) > 0:
                            total_projections += len(camera_projections)
                            cameras_with_proj += 1
                except:
                    pass
                
                stats['projections_count'] = total_projections
                stats['cameras_with_projections'] = cameras_with_proj
            
            # ä¼°ç®—åŸå§‹å†…å­˜ä½¿ç”¨
            stats['estimated_memory'] = get_tie_points_memory_estimate(tie_points)
            
            # ğŸ†• ä¼°ç®—export_colmapè„šæœ¬çš„å†…å­˜ä½¿ç”¨
            stats['export_colmap_memory'] = estimate_export_colmap_memory_usage(frame)
    
    except Exception as e:
        print(f"åˆ†æframeæ—¶å‡ºé”™: {e}")
    
    return stats

def analyze_chunk_statistics(chunk):
    """åˆ†æå•ä¸ªchunkçš„ç»Ÿè®¡ä¿¡æ¯"""
    stats = {
        'frames_count': 0,
        'total_points': 0,
        'total_tracks': 0,
        'total_projections': 0,
        'cameras_count': 0,
        'sensors_count': 0,
        'estimated_memory': 0,
        'frames_stats': [],
        'total_export_colmap_memory': 0,  # ğŸ†• æ€»çš„export_colmapå†…å­˜
        'export_memory_breakdown': {}     # ğŸ†• è¯¦ç»†å†…å­˜åˆ†è§£
    }
    
    if not chunk:
        return stats
    
    try:
        # ç»Ÿè®¡ç›¸æœºæ•°é‡
        if hasattr(chunk, 'cameras') and chunk.cameras:
            stats['cameras_count'] = len(chunk.cameras)
        
        # ç»Ÿè®¡ä¼ æ„Ÿå™¨æ•°é‡
        if hasattr(chunk, 'sensors') and chunk.sensors:
            stats['sensors_count'] = len(chunk.sensors)
        
        # åˆ†æframes
        if hasattr(chunk, 'frames') and chunk.frames:
            stats['frames_count'] = len(chunk.frames)
            
            total_tracks_memory = 0
            total_images_memory = 0
            total_export_memory = 0
            
            for i, frame in enumerate(chunk.frames):
                frame_stats = analyze_frame_statistics(frame)
                frame_stats['frame_index'] = i
                stats['frames_stats'].append(frame_stats)
                
                # ç´¯è®¡ç»Ÿè®¡
                stats['total_points'] += frame_stats['points_count']
                stats['total_tracks'] += frame_stats['tracks_count']
                stats['total_projections'] += frame_stats['projections_count']
                stats['estimated_memory'] += frame_stats['estimated_memory']
                
                # ğŸ†• ç´¯è®¡export_colmapå†…å­˜ç»Ÿè®¡
                export_mem = frame_stats['export_colmap_memory']
                if export_mem:
                    total_tracks_memory += export_mem.get('tracks_dict_memory', 0)
                    total_images_memory += export_mem.get('images_dict_memory', 0)
                    total_export_memory += export_mem.get('total_export_memory', 0)
            
            # ğŸ†• è®¾ç½®æ€»çš„exportå†…å­˜ç»Ÿè®¡
            stats['total_export_colmap_memory'] = total_export_memory
            stats['export_memory_breakdown'] = {
                'total_tracks_dict_memory': total_tracks_memory,
                'total_images_dict_memory': total_images_memory,
                'memory_amplification_ratio': total_export_memory / max(1, stats['estimated_memory']),
                'tracks_dict_percentage': (total_tracks_memory / max(1, total_export_memory)) * 100,
                'images_dict_percentage': (total_images_memory / max(1, total_export_memory)) * 100
            }
    
    except Exception as e:
        print(f"åˆ†æchunkæ—¶å‡ºé”™: {e}")
    
    return stats

def assess_memory_risk(peak_memory_bytes):
    """è¯„ä¼°å†…å­˜ä½¿ç”¨é£é™©"""
    peak_memory_gb = peak_memory_bytes / (1024**3)
    
    if peak_memory_gb < 8:
        return "ä½é£é™© - å¤§å¤šæ•°ç³»ç»Ÿå¯ä»¥å¤„ç†"
    elif peak_memory_gb < 16:
        return "ä¸­ç­‰é£é™© - éœ€è¦16GB+å†…å­˜"
    elif peak_memory_gb < 32:
        return "é«˜é£é™© - éœ€è¦32GB+å†…å­˜ï¼Œå¯èƒ½å‡ºç°å†…å­˜äº¤æ¢"
    elif peak_memory_gb < 64:
        return "æé«˜é£é™© - éœ€è¦64GB+å†…å­˜ï¼Œå¾ˆå¯èƒ½å´©æºƒ"
    else:
        return "å±é™© - å‡ ä¹è‚¯å®šä¼šå´©æºƒï¼Œéœ€è¦å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬"

def analyze_document_statistics():
    """åˆ†ææ•´ä¸ªdocumentçš„ç»Ÿè®¡ä¿¡æ¯"""
    print("å¼€å§‹åˆ†æMetashapeé¡¹ç›®ç»Ÿè®¡ä¿¡æ¯...")
    
    doc = Metashape.app.document
    
    # è·å–åˆå§‹å†…å­˜ä½¿ç”¨æƒ…å†µ
    initial_memory = get_memory_usage()
    
    stats = {
        'chunks_count': 0,
        'total_frames': 0,
        'total_points': 0,
        'total_tracks': 0,
        'total_projections': 0,
        'total_cameras': 0,
        'total_sensors': 0,
        'estimated_memory': 0,
        'chunks_stats': [],
        'memory_info': initial_memory,
        'total_export_colmap_memory': 0,    # ğŸ†• æ€»çš„export_colmapå†…å­˜
        'export_memory_summary': {}         # ğŸ†• exportå†…å­˜æ‘˜è¦
    }
    
    try:
        # åˆ†æchunks
        if hasattr(doc, 'chunks') and doc.chunks:
            stats['chunks_count'] = len(doc.chunks)
            
            total_export_memory = 0
            total_tracks_memory = 0
            total_images_memory = 0
            
            for i, chunk in enumerate(doc.chunks):
                print(f"æ­£åœ¨åˆ†æchunk {i+1}/{stats['chunks_count']}...")
                
                chunk_stats = analyze_chunk_statistics(chunk)
                chunk_stats['chunk_index'] = i
                chunk_stats['chunk_label'] = chunk.label if hasattr(chunk, 'label') else f"Chunk_{i}"
                stats['chunks_stats'].append(chunk_stats)
                
                # ç´¯è®¡ç»Ÿè®¡
                stats['total_frames'] += chunk_stats['frames_count']
                stats['total_points'] += chunk_stats['total_points']
                stats['total_tracks'] += chunk_stats['total_tracks']
                stats['total_projections'] += chunk_stats['total_projections']
                stats['total_cameras'] += chunk_stats['cameras_count']
                stats['total_sensors'] += chunk_stats['sensors_count']
                stats['estimated_memory'] += chunk_stats['estimated_memory']
                
                # ğŸ†• ç´¯è®¡export_colmapå†…å­˜ç»Ÿè®¡
                total_export_memory += chunk_stats['total_export_colmap_memory']
                if 'export_memory_breakdown' in chunk_stats:
                    breakdown = chunk_stats['export_memory_breakdown']
                    total_tracks_memory += breakdown.get('total_tracks_dict_memory', 0)
                    total_images_memory += breakdown.get('total_images_dict_memory', 0)
            
            # ğŸ†• è®¾ç½®æ€»çš„exportå†…å­˜æ‘˜è¦
            stats['total_export_colmap_memory'] = total_export_memory
            current_memory = stats['estimated_memory']
            
            stats['export_memory_summary'] = {
                'total_tracks_dict_memory': total_tracks_memory,
                'total_images_dict_memory': total_images_memory,
                'current_metashape_memory': current_memory,
                'export_script_additional_memory': total_export_memory,
                'peak_memory_during_export': current_memory + total_export_memory,
                'memory_amplification_factor': (total_export_memory / max(1, current_memory)),
                'tracks_dict_percentage': (total_tracks_memory / max(1, total_export_memory)) * 100,
                'images_dict_percentage': (total_images_memory / max(1, total_export_memory)) * 100,
                'risk_assessment': assess_memory_risk(current_memory + total_export_memory)
            }
    
    except Exception as e:
        print(f"åˆ†ædocumentæ—¶å‡ºé”™: {e}")
    
    return stats

def export_statistics_to_file(stats, filepath):
    """å°†ç»Ÿè®¡ä¿¡æ¯å¯¼å‡ºåˆ°æ–‡ä»¶"""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("Metashapeé¡¹ç›®ç»Ÿè®¡æŠ¥å‘Šï¼ˆåŒ…å«export_colmapå†…å­˜åˆ†æï¼‰\n")
            f.write("=" * 60 + "\n\n")
            
            # å†…å­˜ä¿¡æ¯
            memory_info = stats['memory_info']
            f.write("ç³»ç»Ÿå†…å­˜ä¿¡æ¯:\n")
            f.write(f"  ç‰©ç†å†…å­˜ä½¿ç”¨: {format_bytes(memory_info['rss'])}\n")
            f.write(f"  è™šæ‹Ÿå†…å­˜ä½¿ç”¨: {format_bytes(memory_info['vms'])}\n")
            f.write(f"  å†…å­˜ä½¿ç”¨ç™¾åˆ†æ¯”: {memory_info['percent']:.2f}%\n")
            f.write(f"  å¯ç”¨å†…å­˜: {format_bytes(memory_info['available'])}\n\n")
            
            # æ€»ä½“ç»Ÿè®¡
            f.write("é¡¹ç›®æ€»ä½“ç»Ÿè®¡:\n")
            f.write(f"  Chunksæ•°é‡: {stats['chunks_count']}\n")
            f.write(f"  Framesæ€»æ•°: {stats['total_frames']}\n")
            f.write(f"  Pointsæ€»æ•°: {stats['total_points']:,}\n")
            f.write(f"  Tracksæ€»æ•°: {stats['total_tracks']:,}\n")
            f.write(f"  Projectionsæ€»æ•°: {stats['total_projections']:,}\n")
            f.write(f"  Camerasæ€»æ•°: {stats['total_cameras']}\n")
            f.write(f"  Sensorsæ€»æ•°: {stats['total_sensors']}\n")
            f.write(f"  å½“å‰Metashapeå†…å­˜: {format_bytes(stats['estimated_memory'])}\n\n")
            
            # ğŸ†• Export_colmapå†…å­˜åˆ†æ
            if 'export_memory_summary' in stats:
                export_summary = stats['export_memory_summary']
                f.write("Export_colmapè„šæœ¬å†…å­˜åˆ†æ:\n")
                f.write("-" * 40 + "\n")
                f.write(f"  Trackså­—å…¸å†…å­˜: {format_bytes(export_summary.get('total_tracks_dict_memory', 0))}\n")
                f.write(f"  Imageså­—å…¸å†…å­˜: {format_bytes(export_summary.get('total_images_dict_memory', 0))}\n")
                f.write(f"  è„šæœ¬é¢å¤–å†…å­˜: {format_bytes(export_summary.get('export_script_additional_memory', 0))}\n")
                f.write(f"  å¯¼å‡ºæ—¶å³°å€¼å†…å­˜: {format_bytes(export_summary.get('peak_memory_during_export', 0))}\n")
                f.write(f"  å†…å­˜æ”¾å¤§å€æ•°: {export_summary.get('memory_amplification_factor', 0):.2f}x\n")
                f.write(f"  Trackså­—å…¸å æ¯”: {export_summary.get('tracks_dict_percentage', 0):.1f}%\n")
                f.write(f"  Imageså­—å…¸å æ¯”: {export_summary.get('images_dict_percentage', 0):.1f}%\n")
                f.write(f"  é£é™©è¯„ä¼°: {export_summary.get('risk_assessment', 'Unknown')}\n\n")
            
            # è¯¦ç»†chunkç»Ÿè®¡
            for chunk_stats in stats['chunks_stats']:
                f.write(f"Chunk {chunk_stats['chunk_index']}: {chunk_stats['chunk_label']}\n")
                f.write("-" * 40 + "\n")
                f.write(f"  Framesæ•°é‡: {chunk_stats['frames_count']}\n")
                f.write(f"  Pointsæ€»æ•°: {chunk_stats['total_points']:,}\n")
                f.write(f"  Tracksæ€»æ•°: {chunk_stats['total_tracks']:,}\n")
                f.write(f"  Projectionsæ€»æ•°: {chunk_stats['total_projections']:,}\n")
                f.write(f"  Camerasæ•°é‡: {chunk_stats['cameras_count']}\n")
                f.write(f"  Sensorsæ•°é‡: {chunk_stats['sensors_count']}\n")
                f.write(f"  Metashapeå†…å­˜: {format_bytes(chunk_stats['estimated_memory'])}\n")
                
                # ğŸ†• Chunkçº§åˆ«çš„export_colmapå†…å­˜åˆ†æ
                if 'export_memory_breakdown' in chunk_stats:
                    breakdown = chunk_stats['export_memory_breakdown']
                    f.write(f"  Export_colmapåˆ†æ:\n")
                    f.write(f"    Trackså­—å…¸: {format_bytes(breakdown.get('total_tracks_dict_memory', 0))}\n")
                    f.write(f"    Imageså­—å…¸: {format_bytes(breakdown.get('total_images_dict_memory', 0))}\n")
                    f.write(f"    å†…å­˜æ”¾å¤§: {breakdown.get('memory_amplification_ratio', 0):.2f}x\n")
                
                # Frameè¯¦ç»†ä¿¡æ¯
                if chunk_stats['frames_stats']:
                    f.write("  Frameè¯¦æƒ…:\n")
                    for frame_stats in chunk_stats['frames_stats']:
                        export_mem = frame_stats.get('export_colmap_memory', {})
                        f.write(f"    Frame {frame_stats['frame_index']}: ")
                        f.write(f"Points={frame_stats['points_count']:,}, ")
                        f.write(f"Tracks={frame_stats['tracks_count']:,}, ")
                        f.write(f"Projections={frame_stats['projections_count']:,}, ")
                        f.write(f"Metashapeå†…å­˜={format_bytes(frame_stats['estimated_memory'])}")
                        if export_mem:
                            f.write(f", Exportå†…å­˜={format_bytes(export_mem.get('total_export_memory', 0))}")
                        f.write("\n")
                f.write("\n")
        
        return True
    except Exception as e:
        print(f"å¯¼å‡ºç»Ÿè®¡ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        return False

class ProjectStatsGUI(QtWidgets.QDialog):
    def __init__(self, parent=None):
        super(ProjectStatsGUI, self).__init__(parent)
        self.setWindowTitle("Metashapeé¡¹ç›®ç»Ÿè®¡åˆ†æ (å«Export_colmapå†…å­˜åˆ†æ)")
        self.setMinimumSize(900, 700)
        self.stats = None
        self.setup_ui()

    def setup_ui(self):
        layout = QtWidgets.QVBoxLayout()
        
        # æ ‡é¢˜
        title_label = QtWidgets.QLabel("Metashapeé¡¹ç›®ç»Ÿè®¡åˆ†æ")
        title_label.setAlignment(QtCore.Qt.AlignCenter)
        title_label.setStyleSheet("font-size: 16px; font-weight: bold; margin: 10px;")
        layout.addWidget(title_label)
        
        # è¯´æ˜æ–‡æœ¬
        info_label = QtWidgets.QLabel("æœ¬å·¥å…·å¯åˆ†æé¡¹ç›®æ•°æ®ç»“æ„å¹¶é¢„æµ‹export_colmapè„šæœ¬çš„å†…å­˜ä½¿ç”¨")
        info_label.setAlignment(QtCore.Qt.AlignCenter)
        info_label.setStyleSheet("color: #666; margin-bottom: 10px;")
        layout.addWidget(info_label)
        
        # æŒ‰é’®åŒºåŸŸ
        button_layout = QtWidgets.QHBoxLayout()
        
        self.analyze_btn = QtWidgets.QPushButton("å¼€å§‹åˆ†æ")
        self.analyze_btn.setFixedSize(120, 30)
        self.analyze_btn.clicked.connect(self.run_analysis)
        
        self.export_btn = QtWidgets.QPushButton("å¯¼å‡ºæŠ¥å‘Š")
        self.export_btn.setFixedSize(120, 30)
        self.export_btn.setEnabled(False)
        self.export_btn.clicked.connect(self.export_report)
        
        self.close_btn = QtWidgets.QPushButton("å…³é—­")
        self.close_btn.setFixedSize(120, 30)
        self.close_btn.clicked.connect(self.close)
        
        button_layout.addWidget(self.analyze_btn)
        button_layout.addWidget(self.export_btn)
        button_layout.addStretch()
        button_layout.addWidget(self.close_btn)
        
        layout.addLayout(button_layout)
        
        # è¿›åº¦æ¡
        self.progress_bar = QtWidgets.QProgressBar()
        self.progress_bar.setVisible(False)
        layout.addWidget(self.progress_bar)
        
        # ç»“æœæ˜¾ç¤ºåŒºåŸŸ
        self.result_text = QtWidgets.QTextEdit()
        self.result_text.setReadOnly(True)
        self.result_text.setFont(QtGui.QFont("Consolas", 9))
        layout.addWidget(self.result_text)
        
        self.setLayout(layout)

    def run_analysis(self):
        self.analyze_btn.setEnabled(False)
        self.export_btn.setEnabled(False)
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 0)  # ä¸ç¡®å®šè¿›åº¦
        self.result_text.clear()
    def run_analysis(self):
        self.analyze_btn.setEnabled(False)
        self.export_btn.setEnabled(False)
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 0)  # ä¸ç¡®å®šè¿›åº¦
        self.result_text.clear()
        self.result_text.append("æ­£åœ¨åˆ†æé¡¹ç›®...")
        
        QtWidgets.QApplication.processEvents()
        
        try:
            # è¿è¡Œåˆ†æ
            self.stats = analyze_document_statistics()
            self.display_results()
            self.export_btn.setEnabled(True)
            
        except Exception as e:
            self.result_text.append(f"\nåˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            
        finally:
            self.progress_bar.setVisible(False)
            self.analyze_btn.setEnabled(True)

    def display_results(self):
        if not self.stats:
            return
        
        self.result_text.clear()
        
        # ç³»ç»Ÿå†…å­˜ä¿¡æ¯
        memory_info = self.stats['memory_info']
        self.result_text.append("=== ç³»ç»Ÿå†…å­˜ä¿¡æ¯ ===")
        self.result_text.append(f"ç‰©ç†å†…å­˜ä½¿ç”¨: {format_bytes(memory_info['rss'])}")
        self.result_text.append(f"è™šæ‹Ÿå†…å­˜ä½¿ç”¨: {format_bytes(memory_info['vms'])}")
        self.result_text.append(f"å†…å­˜ä½¿ç”¨ç™¾åˆ†æ¯”: {memory_info['percent']:.2f}%")
        self.result_text.append(f"å¯ç”¨å†…å­˜: {format_bytes(memory_info['available'])}")
        self.result_text.append("")
        
        # é¡¹ç›®æ€»ä½“ç»Ÿè®¡
        self.result_text.append("=== é¡¹ç›®æ€»ä½“ç»Ÿè®¡ ===")
        self.result_text.append(f"Chunksæ•°é‡: {self.stats['chunks_count']}")
        self.result_text.append(f"Framesæ€»æ•°: {self.stats['total_frames']}")
        self.result_text.append(f"Pointsæ€»æ•°: {self.stats['total_points']:,}")
        self.result_text.append(f"Tracksæ€»æ•°: {self.stats['total_tracks']:,}")
        self.result_text.append(f"Projectionsæ€»æ•°: {self.stats['total_projections']:,}")
        self.result_text.append(f"Camerasæ€»æ•°: {self.stats['total_cameras']}")
        self.result_text.append(f"Sensorsæ€»æ•°: {self.stats['total_sensors']}")
        self.result_text.append(f"å½“å‰Metashapeå†…å­˜: {format_bytes(self.stats['estimated_memory'])}")
        self.result_text.append("")
        
        # ğŸ†• Export_colmapå†…å­˜åˆ†æ
        if 'export_memory_summary' in self.stats:
            export_summary = self.stats['export_memory_summary']
            self.result_text.append("=== Export_colmapè„šæœ¬å†…å­˜åˆ†æ ===")
            self.result_text.append(f"Trackså­—å…¸é¢„è®¡å†…å­˜: {format_bytes(export_summary.get('total_tracks_dict_memory', 0))}")
            self.result_text.append(f"Imageså­—å…¸é¢„è®¡å†…å­˜: {format_bytes(export_summary.get('total_images_dict_memory', 0))}")
            self.result_text.append(f"è„šæœ¬é¢å¤–å†…å­˜éœ€æ±‚: {format_bytes(export_summary.get('export_script_additional_memory', 0))}")
            self.result_text.append(f"å¯¼å‡ºæ—¶å³°å€¼å†…å­˜: {format_bytes(export_summary.get('peak_memory_during_export', 0))}")
            self.result_text.append(f"å†…å­˜æ”¾å¤§å€æ•°: {export_summary.get('memory_amplification_factor', 0):.2f}x")
            
            # é£é™©è¯„ä¼°ç”¨é¢œè‰²æ ‡æ³¨
            risk = export_summary.get('risk_assessment', 'Unknown')
            if "ä½é£é™©" in risk:
                risk_color = "ğŸŸ¢"
            elif "ä¸­ç­‰é£é™©" in risk:
                risk_color = "ğŸŸ¡"
            elif "é«˜é£é™©" in risk:
                risk_color = "ğŸŸ "
            else:
                risk_color = "ğŸ”´"
            
            self.result_text.append(f"é£é™©è¯„ä¼°: {risk_color} {risk}")
            self.result_text.append("")
            
            # å†…å­˜ä½¿ç”¨åˆ†è§£
            tracks_pct = export_summary.get('tracks_dict_percentage', 0)
            images_pct = export_summary.get('images_dict_percentage', 0)
            self.result_text.append("å†…å­˜ä½¿ç”¨åˆ†è§£:")
            self.result_text.append(f"  Trackså­—å…¸: {tracks_pct:.1f}%")
            self.result_text.append(f"  Imageså­—å…¸: {images_pct:.1f}%")
            self.result_text.append(f"  å…¶ä»–å¼€é”€: {(100-tracks_pct-images_pct):.1f}%")
            self.result_text.append("")
        
        # è¯¦ç»†chunkç»Ÿè®¡
        self.result_text.append("=== Chunkè¯¦ç»†ç»Ÿè®¡ ===")
        for chunk_stats in self.stats['chunks_stats']:
            self.result_text.append(f"Chunk {chunk_stats['chunk_index']}: {chunk_stats['chunk_label']}")
            self.result_text.append(f"  Frames: {chunk_stats['frames_count']}")
            self.result_text.append(f"  Points: {chunk_stats['total_points']:,}")
            self.result_text.append(f"  Tracks: {chunk_stats['total_tracks']:,}")
            self.result_text.append(f"  Projections: {chunk_stats['total_projections']:,}")
            self.result_text.append(f"  Cameras: {chunk_stats['cameras_count']}")
            self.result_text.append(f"  Metashapeå†…å­˜: {format_bytes(chunk_stats['estimated_memory'])}")
            
            # ğŸ†• æ˜¾ç¤ºexport_colmapå†…å­˜åˆ†æ
            if 'export_memory_breakdown' in chunk_stats:
                breakdown = chunk_stats['export_memory_breakdown']
                self.result_text.append(f"  Export_colmapå†…å­˜åˆ†æ:")
                total_export = chunk_stats.get('total_export_colmap_memory', 0)
                self.result_text.append(f"    æ€»é¢å¤–å†…å­˜: {format_bytes(total_export)}")
                self.result_text.append(f"    Trackså­—å…¸: {format_bytes(breakdown.get('total_tracks_dict_memory', 0))}")
                self.result_text.append(f"    Imageså­—å…¸: {format_bytes(breakdown.get('total_images_dict_memory', 0))}")
                self.result_text.append(f"    å†…å­˜æ”¾å¤§: {breakdown.get('memory_amplification_ratio', 0):.2f}x")
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªframeçš„ä¿¡æ¯
            if chunk_stats['frames_stats']:
                self.result_text.append("  Frameç»Ÿè®¡:")
                for i, frame_stats in enumerate(chunk_stats['frames_stats'][:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                    export_mem = frame_stats.get('export_colmap_memory', {})
                    export_total = export_mem.get('total_export_memory', 0)
                    self.result_text.append(f"    Frame {frame_stats['frame_index']}: "
                                          f"Points={frame_stats['points_count']:,}, "
                                          f"Tracks={frame_stats['tracks_count']:,}, "
                                          f"åŸå§‹å†…å­˜={format_bytes(frame_stats['estimated_memory'])}, "
                                          f"Exporté¢å¤–={format_bytes(export_total)}")
                if len(chunk_stats['frames_stats']) > 3:
                    self.result_text.append(f"    ... è¿˜æœ‰ {len(chunk_stats['frames_stats']) - 3} ä¸ªframes")
            
            self.result_text.append("")

    def export_report(self):
        if not self.stats:
            return
        
        filename, _ = QtWidgets.QFileDialog.getSaveFileName(
            self, "ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š", "metashape_stats_report.txt", "Text Files (*.txt)")
        
        if filename:
            if export_statistics_to_file(self.stats, filename):
                QtWidgets.QMessageBox.information(self, "æˆåŠŸ", f"ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜åˆ°:\n{filename}")
            else:
                QtWidgets.QMessageBox.warning(self, "é”™è¯¯", "ä¿å­˜ç»Ÿè®¡æŠ¥å‘Šæ—¶å‡ºç°é”™è¯¯")

def show_project_statistics():
    """æ˜¾ç¤ºé¡¹ç›®ç»Ÿè®¡å¯¹è¯æ¡†"""
    global app
    app = QtWidgets.QApplication.instance()
    parent = app.activeWindow()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ‰“å¼€çš„é¡¹ç›®
    doc = Metashape.app.document
    if not doc or not hasattr(doc, 'chunks'):
        QtWidgets.QMessageBox.warning(None, "è­¦å‘Š", "è¯·å…ˆæ‰“å¼€ä¸€ä¸ªMetashapeé¡¹ç›®")
        return
    
    dialog = ProjectStatsGUI(parent)
    dialog.exec()

# æ³¨å†Œèœå•é¡¹
label = "Scripts/Metashapeé¡¹ç›®ç»Ÿè®¡åˆ†æ (å«Export_colmapå†…å­˜é¢„æµ‹)"
Metashape.app.addMenuItem(label, show_project_statistics)
print(f"To execute this script press {label}")